

# =============================================
# üß± Imports
# =============================================
import pandas as pd
import operator
from typing import Dict, Union, Any, Annotated, Sequence, TypedDict, Literal, Optional, List
from langchain_core.runnables.config import RunnableConfig

import re
from typing import Literal
from groq import APIError

from langchain_openai import ChatOpenAI
from langchain_groq import ChatGroq
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.tools import StructuredTool
#from pydantic import BaseModel

from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt.tool_node import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from src.config import  api_key, OPENAI_API_KEY
from langchain_core.prompts import SystemMessagePromptTemplate
from langchain_core.messages import SystemMessage
#from src.visuals import units_visual_tool_struct
from langchain_core.tools import tool, InjectedToolCallId
from langgraph.types import Command
from langgraph.prebuilt import InjectedState
from psycopg_pool import AsyncConnectionPool
import uuid,json
import psycopg
from psycopg_pool import ConnectionPool
#from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
import os
import asyncio
from src.tools import find_properties_tool, google_maps_link_tool, nearby_places_tool
from src.projects_tools import get_project_info_tool,  compare_projects_tool
from src.python_code_tool import execute_python_query 
from src.search_tool import search_egyptian_real_estate_tavily
from src.market_info_tool import search_market_intelligence
from src.map_tool import analyze_egyptian_neighborhood_advanced
from src.proj_intelligent_tool import get_project_details, semantic_project_search,intelligent_project_matcher, get_project_availability
#from src.user_profile import load_user_profile_by_email,save_user_profile_by_email
# Initialize your datasets (replace with your actual data loading)
projects_df = pd.read_csv("data/projects_cleaned.csv")
units_df = pd.read_csv("data/units_cleaned.csv")

class UserInfo(TypedDict, total=False):
    email: str
    name: str
    preferredLocations: list[str]  # Changed from dict to list
    averageBudget: int
    family_size: int
    is_investor: bool
    


# Define the agent state
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    saved_plots: Annotated[list, operator.add]
    next: str
    user: Optional[UserInfo]
    plan: str  # üÜï Track the execution plan
    completed_steps: Annotated[list, operator.add]  # üÜï Track completed steps
    current_goal: str 

initial_state = {
    "saved_plots": [],
    "user": None,
    "plan": "",
    "completed_steps": [],
    "current_goal": "" # ‚úÖ initialize this once
}


    
 
# Initialize the LLM with tools
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.3, api_key=OPENAI_API_KEY, max_retries=2)
#llm = ChatGroq(model_name="llama-3.1-8b-instant",temperature=0,api_key=api_key)
#llm = ChatGroq(model_name="llama-3.3-70b-versatile",temperature=0,api_key=api_key)
# üÜï VERIFY
print("=" * 50)
print(f"üéØ CONFIRMED ACTIVE MODEL: {llm.model_name}")
print("=" * 50)
tools = [execute_python_query,find_properties_tool, google_maps_link_tool, nearby_places_tool,get_project_details,semantic_project_search,intelligent_project_matcher,
         compare_projects_tool,search_egyptian_real_estate_tavily,search_market_intelligence,analyze_egyptian_neighborhood_advanced,get_project_availability]
llm_with_tools = llm.bind_tools(tools)


# def user_profiling_node(state: AgentState) -> dict:
#     """
#     Continuously learns about the user including frequent places and proximity needs
#     """
#     messages = state.get("messages", [])
#     user_info = state.get("user", {}) or {}
    
#     user_email = user_info.get("email")
    
#     if not user_email:
#         print("‚ö†Ô∏è No email in state - skipping profile persistence")
#         return {}
    
#     # Get last human message
#     last_human_msg = None
#     for msg in reversed(messages):
#         if isinstance(msg, HumanMessage):
#             last_human_msg = msg.content
#             break
    
#     if not last_human_msg:
#         return {}
    
#     # Enhanced profile extraction prompt
#     profiling_prompt = f"""Analyze this conversation and extract ANY new information about the user.

# CONVERSATION: "{last_human_msg}"

# CURRENT PROFILE:
# {json.dumps(user_info, indent=2)}

# Extract and update ALL relevant information:

# 1. **Personal preferences** (location preferences, lifestyle, priorities)
# 2. **Budget hints** (even approximate mentions like "around 5 million", "under 10M")
# 3. **Family details** (size, children, pets mentioned)
# 4. **Investment vs. residence** intent
# 5. **Timeline urgency** (urgent, flexible, specific date)
# 6. **Property requirements** (parking, floors, amenities, balcony, view)
# 7. **Dislikes or deal-breakers** (noisy, ground floor, far from metro)

# üÜï 8. **FREQUENT PLACES** - Extract ANY place the user mentions going to regularly:
#    - Work location (office, business, workplace)
#    - School (for kids)
#    - University (for self or children)
#    - Family locations (parents' house, relatives)
#    - Hobby places (gym, club, mall, sports venue)
#    - Religious places (mosque, church)
#    - Any other regularly visited location
   
#    For each place extract:
#    - type: "work", "school", "university", "family", "hobby", "gym", "hospital", "religious", "shopping", "other"
#    - name: Name of the place/institution (MUST provide if mentioned, use "Unknown [type]" if name not given)
#    - address: Location/area mentioned (MUST provide)
#    - importance: "critical" (must be near), "high" (very important), "medium" (nice to have), "low" (optional)



# Return ONLY a JSON object with NEW/UPDATED fields (empty {{}} if nothing new):
# {{
#   "preferredLocations": ["New Cairo", "Sheikh Zayed"],
#   "averageBudget": 5000000,
#   "family_size": 4,
#   "is_investor": false,
#   "preferences": {{"parking": true, "floor": "not ground", "quiet": true}},
#   "timeline": "urgent",
#   "dislikes": ["noisy areas", "ground floor"],
#   "frequent_places": [
#     {{"type": "work", "name": "Smart Village", "address": "6th October", "importance": "high"}},
#     {{"type": "school", "name": "AIS", "address": "New Cairo", "importance": "critical"}},
#     {{"type": "family", "name": "Parents house", "address": "Maadi", "importance": "medium"}}
#   ],
# }}

# ‚ö†Ô∏è IMPORTANT: For frequent_places, ALWAYS include both "name" and "address" fields. If name not mentioned, use "Unknown School", "Unknown Workplace", etc.

# CRITICAL: Only include fields that were mentioned or implied in the conversation!"""
    
#     try:
#         response = llm.invoke([
#             SystemMessage(content="You are a user profiling expert. Extract information precisely, especially location-based needs."),
#             HumanMessage(content=profiling_prompt)
#         ])
        
#         # Parse response
#         content = response.content.strip()
#         if content.startswith("```"):
#             content = content.split("```")[1]
#             if content.startswith("json"):
#                 content = content[4:]
        
#         updates = json.loads(content)
        
#         if updates:
#             # Merge with existing user info
#             for key, value in updates.items():
#                 if key == "preferredLocations" and key in user_info:
#                     existing = set(user_info.get(key, []))
#                     new_locations = value if isinstance(value, list) else [value]
#                     existing.update(new_locations)
#                     user_info[key] = list(existing)
                    
#                 elif key == "frequent_places":
#                     # üÜï Merge frequent places (avoid duplicates by name+address)
#                     existing_places = user_info.get(key, [])
#                     existing_keys = {(p.get('name', ''), p.get('address', '')) for p in existing_places}
                    
#                     for new_place in value:
#                         # ‚úÖ VALIDATE: Ensure name and address exist
#                         if not new_place.get('name'):
#                             new_place['name'] = f"Unknown {new_place.get('type', 'Place').capitalize()}"
#                         if not new_place.get('address'):
#                             print(f"‚ö†Ô∏è Skipping place without address: {new_place}")
#                             continue
                        
#                         place_key = (new_place.get('name'), new_place.get('address'))
#                         if place_key not in existing_keys:
#                             existing_places.append(new_place)
#                             existing_keys.add(place_key)
#                         else:
#                             # Update importance if new one is higher
#                             importance_order = {"critical": 4, "high": 3, "medium": 2, "low": 1}
#                             for i, existing_place in enumerate(existing_places):
#                                 if (existing_place.get('name'), existing_place.get('address')) == place_key:
#                                     if importance_order.get(new_place.get('importance', 'low'), 0) > \
#                                        importance_order.get(existing_place.get('importance', 'low'), 0):
#                                         existing_places[i]['importance'] = new_place['importance']
                    
#                     user_info[key] = existing_places
                    
                
                    
#                 elif key == "preferences" and key in user_info:
#                     if not isinstance(user_info[key], dict):
#                         user_info[key] = {}
#                     user_info[key].update(value)
                    
#                 elif key == "dislikes" and key in user_info:
#                     existing = set(user_info.get(key, []))
#                     new_dislikes = value if isinstance(value, list) else [value]
#                     existing.update(new_dislikes)
#                     user_info[key] = list(existing)
#                 else:
#                     user_info[key] = value
            
#             print(f"üë§ USER PROFILE UPDATED: {updates}")
            
#             # ‚úÖ FIX: Call the method correctly with self (it's already a method call)
#             try:
#                 save_user_profile_by_email(user_email, user_info)
#                 print(f"üíæ Profile saved to database for {user_email}")
#             except Exception as db_error:
#                 print(f"‚ùå Database save failed: {db_error}")
#                 # Continue anyway - state is updated even if DB save fails
    
#     except json.JSONDecodeError as e:
#         print(f"‚ö†Ô∏è Failed to parse profile update: {e}")
#         print(f"Raw content: {response.content if 'response' in locals() else 'N/A'}")
#     except Exception as e:
#         print(f"‚ö†Ô∏è Profile extraction failed: {e}")
#         import traceback
#         traceback.print_exc()
    
#     return {"user": user_info}







def planning_node(state: AgentState) -> dict:
    """
    Creates a multi-step plan instead of single-intent routing
    """
    messages = state.get("messages", [])
    if not messages:
        return {"messages": []}
    
    last_human_msg = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_human_msg = msg.content
            break
    
    if not last_human_msg:
        return {"messages": []}
    
    user_info = state.get("user", {})

    # frequent_places_str = ""
    # if user_info.get("frequent_places"):
    #     frequent_places_str = "\nüìç FREQUENT PLACES:"
    #     for place in user_info.get("frequent_places", []):
    #         frequent_places_str += f"\n  - {place.get('type').upper()}: {place.get('name')} in {place.get('address')} (importance: {place.get('importance')})"
    
    # Create a planning prompt
    planning_prompt = f"""Analyze this real estate query and create a simple plan.

USER: "{last_human_msg}"
üìä USER CONTEXT:
- Budget: {user_info.get('averageBudget', 'N/A')} EGP
- Preferred Locations: {', '.join(user_info.get('preferredLocations', [])) or 'N/A'}
- Family Size: {user_info.get('family_size', 'N/A')}

## SMART TOOL MATCHING:

### üèòÔ∏è USER ASKS ABOUT PROPERTIES TO BUY/RENT
Use ALL three (combo approach):
1. **intelligent_project_matcher** - Find matching projects by budget/location
2. **semantic_project_search** - If user mentions specific features ("quiet", "modern", "family-friendly")
3. **search_egyptian_real_estate_tavily** - Get online listings with real sources
‚úÖ Return: Projects + online options + sources

### üèôÔ∏è USER ASKS ABOUT AREA/NEIGHBORHOOD QUALITY
Use **analyze_egyptian_neighborhood_advanced** ONLY
‚úÖ When they ask: "Is it quiet?", "Good for families?", "Schools nearby?", "Tell me about [Area]"

### üìä USER ASKS ABOUT MARKET/TRENDS/INVESTMENT
Use **search_market_intelligence** 
USE WHEN USER ASKS ABOUT*:
  ‚úÖ Market Trends: "What are current real estate trends in Egypt?"
  ‚úÖ Investment Advice: "Is it a good time to invest?", "Best ROI areas?"
  ‚úÖ Price Trends: "Are prices going up or down?", "Price appreciation rates?"
  ‚úÖ Laws/Regulations: "Can foreigners buy?", "What are ownership laws?", "Property taxes?"
  ‚úÖ Economic Factors: "How does inflation affect prices?", "Currency impact?"
  ‚úÖ Market Forecasts: "What's the outlook for 2026?", "Future predictions?"
  ‚úÖ Government Policies: "Mortgage programs?", "Government initiatives?"
  ‚úÖ Rental Market: "Typical rental yields?", "Tenant demand?"
  ‚úÖ Developer Activity: "Top developers?", "New project pipelines?"
  ‚úÖ Market Analysis: "Market size?", "Growth rate?", "Market health?"
  ‚úÖ Location Analysis: "Tell me about New Administrative Capital as investment"
  ‚úÖ General Advice: "Should I invest now or wait?", "Risks in Egyptian market?"
    *CRITICAL RULES*:
- DO NOT use this for finding specific properties
- Use for questions, analysis, advice, information
- Great for "why", "how", "should I", "what about" questions


### üè¢ USER ASKS ABOUT SPECIFIC PROJECT
Use **get_project_details** for info
Use **get_project_availability** to check units
‚úÖ When they ask: "Tell me about [Project Name]", "What units are available?"

### üìç USER WANTS PROXIMITY/NEARBY PLACES
Use **find_properties_tool** - Search near locations (work, school)
Use **nearby_places_tool** - Show amenities near a property
‚úÖ When they ask: "Near my office?", "What's around [Project]?", "Schools nearby?"

### üìà USER NEEDS ANALYSIS/STATISTICS
Use **execute_python_query** with smart functions
‚úÖ When they ask: "Compare prices", "Budget breakdown", "Stats by area"

---

## DECISION RULES (Pick 1-3 tools):

**Property Search** ‚Üí intelligent_project_matcher + semantic_project_search + search_egyptian_real_estate_tavily
**Area Info** ‚Üí analyze_egyptian_neighborhood_advanced (+ nearby_places_tool if asking about amenities)
**Market Info** ‚Üí search_market_intelligence (include sources)
**Specific Project** ‚Üí get_project_details + get_project_availability
**Proximity** ‚Üí find_properties_tool + nearby_places_tool
**Stats/Analysis** ‚Üí execute_python_query

---

## PLAN FORMAT:
1. [Tool Name] - Why we need it
2. [Tool Name] - Why we need it (optional)
3. [Tool Name] - Why we need it (optional)

Keep it short. 1 tool for simple questions, max 3 for complex ones.
Always mention sources when using search_market_intelligence"""
    
    # Get planning from LLM
    planning_msg = llm.invoke([
        SystemMessage(content="You are a real estate planning expert. Create concise step-by-step plans."),
        HumanMessage(content=planning_prompt)
    ])
    
    # Add plan to state
    plan_content = f"""
üéØ **EXECUTION PLAN**:
{planning_msg.content}

I'll now execute this plan step by step...
"""
    
    return {"messages": [SystemMessage(content=plan_content)], "plan": planning_msg.content}


def clean_messages_for_token_limit(messages, max_messages=4):
    """Keep only essential messages to stay under token limit"""
    if len(messages) <= max_messages:
        return messages
    
    print(f"üßπ Cleaning messages: {len(messages)} ‚Üí {max_messages}")
    
    # Strategy: Keep system + last user + last assistant + last tool result
    cleaned = []
    
    # 1. Keep system message (if exists)
    system_msgs = [msg for msg in messages if msg.type == "system"]
    if system_msgs:
        cleaned.append(system_msgs[0])
    
    # 2. Keep last user message
    user_msgs = [msg for msg in messages if msg.type == "human"]
    if user_msgs:
        cleaned.append(user_msgs[-1])
    
    # 3. Keep last assistant message
    ai_msgs = [msg for msg in messages if msg.type == "ai"]
    if ai_msgs:
        cleaned.append(ai_msgs[-1])
    
    # 4. Keep only the most recent tool message
    tool_msgs = []
    for msg in messages:
        if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs.get('tool_calls'):
            tool_msgs.append(msg)
        elif hasattr(msg, 'tool_calls') and msg.tool_calls:
            tool_msgs.append(msg)
    
    if tool_msgs:
        cleaned.append(tool_msgs[-1])  # Only keep most recent tool call
    
    return cleaned

def reasoning_agent_node(state: AgentState) -> AgentState:
    """
    Enhanced agent that reasons about which tools to call based on the plan
    """
    messages = state.get("messages", [])
    #messages = clean_messages_for_token_limit(state["messages"], max_messages=4)
    user_info = state.get("user", {})
    plan = state.get("plan", "")

    # frequent_places_context = ""
    # if user_info.get("frequent_places"):
    #     frequent_places_context = "\n\nüó∫Ô∏è **USER'S FREQUENT PLACES**:"
    #     for place in user_info.get("frequent_places", []):
    #         frequent_places_context += f"\n  - **{place.get('type').capitalize()}**: {place.get('name')} ({place.get('address')}) - {place.get('importance')} priority"
        
    #     frequent_places_context += "\n\n‚ö†Ô∏è **ALWAYS verify proximity to these places when recommending properties!**"
    
    # Build reasoning context
    # üÜï PERSONAL CONTEXT (from your existing code)
    personal_context = f"""
üéØ ACTIVE USER: **{user_info.get('name', 'User')}**

üìä USER PROFILE:
- Locations: {', '.join(user_info.get('preferredLocations', [])) or '‚ùå Not set'}
- Budget: {user_info.get('averageBudget', '‚ùå Not set')} EGP
- Family: {user_info.get('family_size', '‚ùå Unknown')} members
- Type: {'üèóÔ∏è Investor' if user_info.get('is_investor') else 'üè† Residence'}



‚ö†Ô∏è **When recommending properties, ALWAYS consider proximity to frequent places!**
"""
    
    # üÜï UPDATED SYSTEM CONTEXT (replace the old reasoning_context)
    
    system_context = f"""You are a smart real estate AI assistant. Think before you act.

{personal_context}

PLAN: {plan}

---

## STEP 1: UNDERSTAND THE USER'S CORE NEED (Think)
Before executing tools:
- What is the user REALLY asking? (property search, area advice, investment decision?)
- What matters to them? (budget, family, commute, lifestyle, investment ROI?)
- Extract: budget, location, family size, specific concerns from context
- Use user's requirements IF given, else use context info

---

## STEP 2: EXECUTE THE PLAN (Act)
Run the tools from your plan above with actual parameters.

---

## STEP 3: SYNTHESIZE & PERSONALIZE (Reason & Format)
‚úÖ DON'T: Just list tool outputs
‚úÖ DO: 
- Reference user's specific situation ("Based on your 2M budget and family of 4...")
- Interpret results in their context ("This area is good for you because...")
- Compare options if multiple ("Property A is closer to your work, Property B is quieter...")
- Flag concerns ("Note: Area B has limited schools nearby")
- Make clear recommendations ("I suggest focusing on...")

---

## ANSWER STRUCTURE:

1Ô∏è‚É£ **OPENING** (1-2 sentences)- do not explictly right opening this is just to show you structure
   - Acknowledge their question
   - Reference their specific situation

2Ô∏è‚É£ **FINDINGS** (Tool outputs formatted naturally)-do not explictly right findings this is just to show you structure
   - For properties: "Here are the best options for you..."
   - For areas: "This neighborhood is ideal because..."
   - Weave results into narrative, not bullet lists
   - Include links/sources but integrated, not raw

3Ô∏è‚É£ **PERSONALIZED ANALYSIS** (2-3 sentences)
   - What do these results mean FOR THEM?
   - How does it match their needs?
   - Any trade-offs to consider?

4Ô∏è‚É£ **SUMMARY & SUGGESTIONS** (3-5 points)
   - Top 2-3 recommendations for them specifically
   - Next steps ("Would you like to know more about X?")
   - Questions to consider ("How important is school proximity?")

---

## TOOL EXECUTION REFERENCE:

search_egyptian_real_estate_tavily(
    location="New Cairo",
    bedrooms=3,
    max_price=8000000
)

analyze_egyptian_neighborhood_advanced(
    neighborhood="Rehab",
    user_scenario="family",
    specific_needs=["schools", "parks"]
)

search_market_intelligence(
    query="What are the current investment trends in Egyptian real estate?"
)

get_project_details(project_name="Palm Hills")

get_project_availability(project_name="Palm Hills", bedrooms=3)

nearby_places_tool(project_name="Palm Hills", radius_m=2000)

find_properties_tool(place_name="German University in Cairo", radius_km=5)

execute_python_query(code="get_market_summary()")

---

## CRITICAL RULES:
1. ‚úÖ Always reference user's personal context (budget, family, location preferences)
2. ‚úÖ Format as flowing narrative, not tool dumps
3. ‚úÖ Include links/sources but naturally integrated
4. ‚úÖ End with 2-3 personalized suggestions
5. ‚úÖ Be friendly, clear, and conversational, make the user feel like its taking to someone not a robot
6. ‚úÖ Flag risks or trade-offs relevant to them
7. ‚úÖ Ask follow-up questions to refine future searches

Execute the plan now using this reasoning approach."""
    
    # Add reasoning to messages
    enhanced_messages = [SystemMessage(content=system_context)] + clean_messages_for_groq(messages)
    
    response = llm_with_tools.invoke(enhanced_messages)
    
    # Log reasoning decision
    if response.tool_calls:
        tool_names = [tc.get('name') for tc in response.tool_calls]
        print(f"ü§î REASONING: Calling tools {tool_names} to advance the plan")
    else:
        print("ü§î REASONING: Providing final answer - plan complete")
    
    return {"messages": [response], "next": "tools" if response.tool_calls else "end"}

def get_recent_tool_results(messages):
    """Extract recent tool results for context"""
    recent_results = []
    for msg in reversed(messages[:10]):  # Last 10 messages
        if isinstance(msg, ToolMessage):
            result_preview = str(msg.content)[:200] + "..." if len(str(msg.content)) > 200 else str(msg.content)
            recent_results.append(f"Tool Result: {result_preview}")
        elif isinstance(msg, AIMessage) and msg.tool_calls:
            recent_results.append(f"Tool Called: {[tc.get('name') for tc in msg.tool_calls]}")
    
    return "\n".join(recent_results[-3:]) if recent_results else "No recent tool results"





def tool_node(state: AgentState) -> dict:
    """Execute the tools that the agent called and update the state correctly."""
    
    messages = state.get("messages", [])
    if not messages:
        return {"messages": [], "next": "end"}

    last_message = messages[-1]
    tool_results = []
    state_updates = {}

    # Loop over tool_calls produced by the agent's AIMessage (if any)
    for tool_call in getattr(last_message, "tool_calls", []) or []:
        # ‚úÖ VALIDATE tool_call structure BEFORE processing
        if not isinstance(tool_call, dict):
            print(f"‚ö†Ô∏è Skipping non-dict tool_call: {tool_call}")
            continue
            
        tool_name = tool_call.get("name")
        tool_args = tool_call.get("args", {})
        tool_call_id = tool_call.get("id")

        # ‚úÖ CRITICAL: Ensure args is always a valid dict
        if tool_args is None:
            tool_args = {}
        elif not isinstance(tool_args, dict):
            print(f"‚ö†Ô∏è Converting non-dict args to dict for tool {tool_name}")
            tool_args = {}

        if not tool_name:
            print(f"‚ö†Ô∏è Skipping tool_call without name: {tool_call}")
            continue
            
        if not tool_call_id:
            tool_call_id = f"call_{uuid.uuid4().hex[:8]}"

        print(f"üîß Executing tool: {tool_name}")
        print(f"üìã Tool arguments: {tool_args}")

        result = None
        
        try:
            # ‚úÖ CREATE FULL TOOL CALL STRUCTURE for tools that need it
            full_tool_call = {
                "name": tool_name,
                "args": tool_args,
                "type": "tool_call",
                "id": tool_call_id
            }

            # ‚úÖ FIXED: Use full tool call structure for tools that require InjectedToolCallId
            if tool_name == "execute_python_query":
                result = execute_python_query.invoke(full_tool_call)

            elif tool_name == "find_properties_tool":
                result = find_properties_tool.invoke(full_tool_call)
                
            elif tool_name == "google_maps_link_tool":
                result = google_maps_link_tool.invoke(full_tool_call)
                
            elif tool_name == "nearby_places_tool":
                result = nearby_places_tool.invoke(full_tool_call)
            
            elif tool_name == "get_project_info_tool":
                result = get_project_info_tool.invoke(full_tool_call)
            
            elif tool_name == "compare_projects_tool":
                result = compare_projects_tool.invoke(full_tool_call)

            elif tool_name == "search_egyptian_real_estate_tavily":
                result = search_egyptian_real_estate_tavily.invoke(full_tool_call)
            
            elif tool_name == "search_market_intelligence":
                result = search_market_intelligence.invoke(full_tool_call)
            
            elif tool_name == "analyze_egyptian_neighborhood_advanced":
                result = analyze_egyptian_neighborhood_advanced.invoke(full_tool_call)
            elif tool_name == "get_project_details":
                result = get_project_details.invoke(full_tool_call)
            elif tool_name == "semantic_project_search":
                result = semantic_project_search.invoke(full_tool_call)
            elif tool_name == "intelligent_project_matcher":
                result = intelligent_project_matcher.invoke(full_tool_call)
            elif tool_name == "get_project_availability":
                result = get_project_availability.invoke(full_tool_call)
                
            else:
                result = f"Unknown tool: {tool_name}"

        except Exception as e:
            result = f"Error executing tool {tool_name}: {str(e)}"
            print(f"‚ùå Tool error: {e}")

        # Handle result
        if isinstance(result, Command):
            print("‚úÖ Tool returned Command - extracting state updates")
            if hasattr(result, 'update') and result.update:
                for key, value in result.update.items():
                    if key == "messages":
                        tool_results.extend(value)
                    elif key == "saved_plots":
                        # ‚úÖ CRITICAL: Properly accumulate plots
                        if key not in state_updates:
                            state_updates[key] = []
                        state_updates[key].extend(value)
                        print(f"‚úÖ Added {len(value)} plot(s) to state updates")
                    else:
                        state_updates[key] = value
        else:
            tool_message = ToolMessage(
                content=str(result), 
                tool_call_id=tool_call_id
            )
            tool_results.append(tool_message)

    

    # Build response
    response = {
        "messages": tool_results,
        "next": "agent"
    }
    response.update(state_updates)
    
    return response

# Define routing logic
def should_continue(state: AgentState) -> Literal["tools", "end"]:
    """Determine whether to continue to tools or end"""
    return state.get("next", "end")

async def setup_postgres_checkpointer(
    connection_string: str = "postgresql://postgres:123456@localhost:5432/langgraph_db"
):
    """
    Setup ASYNC PostgreSQL checkpointer for CopilotKit
    """
    os.add_dll_directory(r"C:\Program Files\PostgreSQL\16\bin")
    
    # ‚úÖ Use AsyncConnectionPool (not ConnectionPool)
    pool = AsyncConnectionPool(
        conninfo=connection_string,
        max_size=20,
        kwargs={"autocommit": True, "prepare_threshold": 0}
    )
    
    # ‚úÖ Create ASYNC checkpointer
    checkpointer = AsyncPostgresSaver(pool)
    
    # ‚úÖ Await setup
    #await checkpointer.setup()
    
    print("‚úÖ PostgreSQL checkpointer initialized successfully")
    
    return checkpointer


async def build_agent(llm,verbose: bool = True,use_postgres: bool = True):
    # Build the graph
    workflow = StateGraph(AgentState)

    # Add nodes with verbose wrapper if needed
    if verbose:
        #workflow.add_node("profiler", lambda state: verbose_wrapper(user_profiling_node, state, "profiler"))
        workflow.add_node("planner", lambda state: verbose_wrapper(planning_node, state, "planner"))
        workflow.add_node("reasoning_agent", lambda state: verbose_wrapper(reasoning_agent_node, state, "reasoning_agent"))
        workflow.add_node("tools", lambda state: verbose_wrapper(tool_node, state, "tools"))
    else:
        
        #workflow.add_node("profiler", user_profiling_node)
        workflow.add_node("planner", planning_node)  # Replace router with planner
        workflow.add_node("reasoning_agent", reasoning_agent_node)  # Enhanced agent
        workflow.add_node("tools", tool_node)

    
    workflow.add_edge(START, "planner")
    workflow.add_edge("planner", "reasoning_agent")
    workflow.add_conditional_edges(
        "reasoning_agent",
      should_continue,
    {"tools": "tools", "end": END}
)
    workflow.add_edge("tools", "reasoning_agent") 
    # workflow.add_edge(START, "profiler")
    # workflow.add_edge("profiler", "planner")
    # workflow.add_edge("planner", "reasoning_agent")
    # workflow.add_conditional_edges(
    #     "reasoning_agent",
    #     should_continue,
    #     {"tools": "tools", "end": END}
    # )
    # workflow.add_edge("tools", "reasoning_agent")


    # ‚úÖ Use PostgreSQL checkpointer
    # if use_postgres and connection_string:
    #     print("‚úÖ Using PostgreSQL checkpointer")
    #     checkpointer =  await setup_postgres_checkpointer(connection_string)
    #     # ‚úÖ Add verification
    #     print("üîç Verifying database connection...")
    #     try:
    #         # Test connection
    #         import psycopg
    #         conn = psycopg.connect(connection_string)
    #         cursor = conn.cursor()
    #         cursor.execute("SELECT COUNT(*) FROM checkpoints")
    #         count = cursor.fetchone()[0]
    #         print(f"‚úÖ Database accessible - {count} existing checkpoints")
    #         cursor.close()
    #         conn.close()
    #     except Exception as e:
    #         print(f"‚ùå Database verification failed: {e}")
        
    # else:
    #     print("‚ö†Ô∏è Using in-memory checkpointer (no persistence)")
    #     print(use_postgres, connection_string)
    checkpointer = MemorySaver()
    return workflow.compile(checkpointer=checkpointer)




#     return result
def verbose_wrapper(node_func, state, node_name):
    """Wrapper to add verbose logging to node execution"""
    print(f"\n{'‚îÄ'*80}")
    print(f"üìç NODE: {node_name.upper()}")
    print(f"{'‚îÄ'*80}")
    config = None
    if isinstance(state, tuple) and len(state) == 2:
        state, config = state
    elif hasattr(state, 'config'):
        config = state.config
    
    # Execute the actual node with config if available
    if config and node_func.__code__.co_argcount == 2:
        result = node_func(state, config)
    else:
        result = node_func(state)

    # ‚úÖ Handle Command return type first
    if isinstance(result, Command):
        print(f"ü™Ñ Node '{node_name}' returned a Command object")

        # Try to inspect the Command contents safely
        update = getattr(result, "update", None)
        if isinstance(update, dict):
            messages = update.get("messages", [])
        else:
            messages = []

        if messages:
            print(f"üì¶ Command contains {len(messages)} messages")
        else:
            print("‚ÑπÔ∏è Command returned with no messages (state update only).")

        # Important: return Command to LangGraph unchanged
        return result

    # ‚úÖ Handle normal dictionary-based states
    elif isinstance(result, dict):
        messages = result.get("messages", [])
    else:
        print(f"‚ö†Ô∏è Unexpected return type from node '{node_name}': {type(result)}")
        return result

    # Display what happened
    if node_name == "agent":
        if messages:
            last_msg = messages[-1]

            if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
                print("ü§î Agent Decision: CALL TOOL")
                for tool_call in last_msg.tool_calls:
                    tool_name = tool_call.get('name', 'unknown')
                    tool_args = tool_call.get('args', {})
                    
                    print(f"\nüîß Tool: {tool_name}")
                    
                    # ‚úÖ FIXED: Display arguments based on tool type
                    if tool_name == "execute_python_query":
                        print(f"üìã Code to execute:")
                        print("‚îÄ" * 40)
                        print(tool_args.get("code", "N/A"))
                        print("‚îÄ" * 40)
                    else:
                        # For other tools, display their arguments
                        print(f"üìã Arguments:")
                        print("‚îÄ" * 40)
                        for key, value in tool_args.items():
                            print(f"  {key}: {value}")
                        print("‚îÄ" * 40)
            else:
                print("ü§î Agent Decision: PROVIDE ANSWER")
                if hasattr(last_msg, "content") and last_msg.content:
                    print(f"\nüí¨ Response: {last_msg.content}")

    elif node_name == "tools":
        if messages:
            print("‚öôÔ∏è  Tool Execution Results:")
            for msg in messages:
                if isinstance(msg, ToolMessage):
                    print("‚îÄ" * 40)
                    print(msg.content)
                    print("‚îÄ" * 40)

    return result











def clean_messages_for_groq(messages):
    """
    Clean messages for CopilotKit compatibility and reduce token usage.
    Keeps the last user message, the last AI message, and ALL tool outputs
    after that user message (so multi-step reasoning is preserved).
    """
    if not messages:
        return []

    # Find index of the last HumanMessage
    last_user_idx = next(
        (i for i in reversed(range(len(messages))) if isinstance(messages[i], HumanMessage)),
        None
    )

    if last_user_idx is None:
        return messages[-3:]  # fallback

    # Keep all messages since last user message (to preserve full reasoning chain)
    cleaned = messages[last_user_idx:]

    # Clean up AI tool_calls structure for safety
    final_cleaned = []
    for msg in cleaned:
        if isinstance(msg, AIMessage):
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                fixed_tool_calls = []
                for idx, call in enumerate(msg.tool_calls):
                    if not isinstance(call, dict):
                        continue
                    fixed_call = {
                        "name": call.get("name"),
                        "id": call.get("id", f"call_{idx}"),
                        "args": call.get("args", {}) if isinstance(call.get("args"), dict) else {},
                        "type": call.get("type"),
                    }
                    fixed_tool_calls.append(fixed_call)
                msg.tool_calls = fixed_tool_calls
        final_cleaned.append(msg)

    print(f"‚úÖ Reduced {len(messages)} ‚Üí {len(final_cleaned)} (kept messages since last user input)")
    return final_cleaned




































